{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1ljfAeHD4UJO55OM7SCnZ8N16SOay9L_2\n",
      "To: d:\\Deep Learning\\Deep-Learning-Assignments\\2020128-A1\\blob\n",
      "100%|██████████| 16.5M/16.5M [00:01<00:00, 8.54MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'blob'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "\n",
    "# Replace 'file_id' with the actual file ID you want to download\n",
    "file_id = '1ljfAeHD4UJO55OM7SCnZ8N16SOay9L_2'\n",
    "\n",
    "# Replace 'output' with the desired output file name\n",
    "output = 'blob'\n",
    "\n",
    "# Use the gdown.download method to download the file\n",
    "gdown.download(f'https://drive.google.com/uc?id={file_id}', output, quiet=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The contents of blob have been extracted to extracted_folder.\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import lzma\n",
    "\n",
    "# Replace 'your_file.tar.xz' with the actual name of your tar.xz file\n",
    "tar_xz_file = 'blob'\n",
    "\n",
    "# Replace 'extracted_folder' with the desired folder name for extraction\n",
    "output_folder = 'extracted_folder'\n",
    "\n",
    "# Open the tar.xz file for reading using the lzma module\n",
    "with lzma.open(tar_xz_file, 'rb') as f:\n",
    "    # Open the tar file for reading\n",
    "    with tarfile.open(fileobj=f, mode='r') as tar:\n",
    "        # Extract all contents to the specified folder\n",
    "        tar.extractall(output_folder)\n",
    "\n",
    "print(f'The contents of {tar_xz_file} have been extracted to {output_folder}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def loading_time_calculator(dataloader):\n",
    "    t1 = time.time()\n",
    "    print(\"hello \",t1)\n",
    "    for data in dataloader:\n",
    "        # print(data)\n",
    "        pass\n",
    "\n",
    "    t2 = time.time()\n",
    "    # print(\"hello2 \", t2)\n",
    "\n",
    "    return t2 - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000\n",
      "37800\n",
      "4200\n",
      "Label: 0, Image Shape: (28, 28)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class CustomDataset:\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.data = self.load_dataset()\n",
    "\n",
    "    def load_dataset(self):\n",
    "        dataset = []\n",
    "        for digit in os.listdir(self.root_dir):\n",
    "            digit_path = os.path.join(self.root_dir, digit)\n",
    "            for image_file in os.listdir(digit_path):\n",
    "                image_path = os.path.join(digit_path, image_file)\n",
    "                label = int(digit)\n",
    "                dataset.append((image_path, label))\n",
    "        return dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "        image = np.array(Image.open(img_path))\n",
    "        return image, label\n",
    "\n",
    "# Example usage:\n",
    "root_dir = 'extracted_folder/MNIST_DATASET/trainingSet/trainingSet'\n",
    "custom_dataset = CustomDataset(root_dir)\n",
    "train_data_custom, val_data_custom = train_test_split(custom_dataset, test_size=0.1, random_state=42)\n",
    "\n",
    "# Print the number of samples in the dataset\n",
    "print(len(custom_dataset))\n",
    "print(len(train_data_custom))\n",
    "print(len(val_data_custom))\n",
    "\n",
    "# Access a sample from the dataset\n",
    "sample_image, sample_label = custom_dataset[0]\n",
    "print(f\"Label: {sample_label}, Image Shape: {sample_image.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataLoader:\n",
    "    def __init__(self, dataset, batch_size, shuffle=True):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = list(range(len(dataset)))\n",
    "        self.current_index = 0\n",
    "\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.current_index >= len(self.indices):\n",
    "            raise StopIteration\n",
    "\n",
    "        batch_indices = self.indices[self.current_index:self.current_index + self.batch_size]\n",
    "        batch_data = [self.dataset[i] for i in batch_indices]\n",
    "\n",
    "        self.current_index += self.batch_size\n",
    "\n",
    "        images, labels = zip(*batch_data)\n",
    "        return np.array(images), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [128, 256, 512, 1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello  1706966084.065113\n",
      "hello  1706966133.1249433\n",
      "hello  1706966139.1442833\n",
      "hello  1706966145.188384\n",
      "[49.05174684524536, 6.0193400382995605, 6.044100761413574, 6.01112174987793]\n"
     ]
    }
   ],
   "source": [
    "custom_time=[]\n",
    "for i in batch_sizes:\n",
    "    custom_dataloader = CustomDataLoader(custom_dataset, i)\n",
    "    duration = loading_time_calculator(custom_dataloader)\n",
    "    custom_time.append(duration)\n",
    "\n",
    "print(custom_time)\n",
    "# for i in range(0, len(custom_dataset), batch_size):\n",
    "#     batch_data = custom_dataset[i:i+batch_size]\n",
    "    # Process the batch as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root='extracted_folder/MNIST_DATASET/trainingSet/trainingSet', transform=transform)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello  1706966156.408645\n",
      "hello  1706966211.8583329\n",
      "hello  1706966228.1346462\n",
      "hello  1706966243.582175\n"
     ]
    }
   ],
   "source": [
    "# time2 = loading_time_calculator(train_loader)\n",
    "\n",
    "torch_time = []\n",
    "for i in batch_sizes:\n",
    "    torch_dataloader = DataLoader(dataset=train_dataset, batch_size=i, shuffle=True, num_workers=4)\n",
    "    duration = loading_time_calculator(torch_dataloader)\n",
    "    torch_time.append(duration)\n",
    "\n",
    "# print(time2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55.44968795776367, 16.276313304901123, 15.447528839111328, 15.693294525146484]\n"
     ]
    }
   ],
   "source": [
    "print(torch_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(batch_sizes, custom_time, label='Custom Dataloader')\n",
    "plt.plot(batch_sizes, torch_time, label='PyTorch Dataloader')\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Loading Time (seconds)')\n",
    "plt.title('Comparison of Loading Time for Custom and PyTorch Dataloader')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataloader = CustomDataLoader(custom_dataset, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  3,   0,   0,   3,   7,   3,   0,   3,   0,  11,   0,   0,   3,\n",
       "           0,   0,   3,   8,   0,   0,   3,   0,   0,   0,   2,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   1,   5,   0,  12,   0,  16,\n",
       "           0,   0,   4,   0,   2,   8,   3,   0,   4,   8,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   2,   0,   0,   0,   1,   2,   1,  12,   0,   8,   0,\n",
       "           0,   6,   0,  11,   0,   0,   6,   7,   2,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   1,   3,   0,   0,   2,   3,   0,   0,   0,  12,   0,   0,\n",
       "          23,   0,   0,   0,   0,  11,   3,   0,   0,   4,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   1,   1,   0,   0,   2,   0,   0,   6,   0,  25,  27, 136,\n",
       "         135, 188,  89,  84,  25,   0,   0,   3,   1,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  4,   0,   0,   0,   0,   0,   0,   0,   3,  88, 247, 236, 255,\n",
       "         249, 250, 227, 240, 136,  37,   1,   0,   2,   2,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  2,   0,   0,   3,   0,   0,   4,  27, 193, 251, 253, 255, 255,\n",
       "         255, 255, 240, 254, 255, 213,  89,   0,   0,  14,   1,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   6,   0,   0,  18,  56, 246, 255, 253, 243, 251,\n",
       "         255, 245, 255, 255, 254, 255, 231, 119,   7,   0,   5,   0,   0,\n",
       "           0,   0],\n",
       "        [  4,   0,   0,  12,  13,   0,  65, 190, 246, 255, 255, 251, 255,\n",
       "         109,  88, 199, 255, 247, 250, 255, 234,  92,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,  10,   1,   0,   0,  18, 163, 248, 255, 235, 216, 150, 128,\n",
       "          45,   6,   8,  22, 212, 255, 255, 252, 172,   0,  15,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   1,   4,   5,   0,   0, 187, 255, 254,  94,  57,   7,   1,\n",
       "           0,   6,   0,   0, 139, 242, 255, 255, 218,  62,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  5,   2,   0,   0,  11,  56, 252, 235, 253,  20,   5,   2,   5,\n",
       "           1,   0,   1,   2,   0,  97, 249, 248, 249, 166,   8,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   2,   0,   0,  70, 255, 255, 245,  25,  10,   0,   0,\n",
       "           1,   0,   4,  10,   0,  10, 255, 246, 250, 155,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  2,   0,   7,  12,   0,  87, 226, 255, 184,   0,   3,   0,  10,\n",
       "           5,   0,   0,   0,   9,   0, 183, 251, 255, 222,  15,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   5,   1,   0,  19, 230, 255, 243, 255,  35,   2,   0,   0,\n",
       "           0,   0,   9,   8,   0,   0,  70, 245, 242, 255,  14,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   4,   3,   0,  19, 251, 239, 255, 247,  30,   1,   0,   4,\n",
       "           4,  14,   0,   0,   2,   0,  47, 255, 255, 247,  21,   0,   0,\n",
       "           0,   0],\n",
       "        [  6,   0,   2,   2,   0, 173, 247, 252, 250,  28,  10,   0,   0,\n",
       "           8,   0,   0,   0,   8,   0,  67, 249, 255, 255,  12,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   6,   3,   0,  88, 255, 251, 255, 188,  21,   0,  15,\n",
       "           0,   8,   2,  16,   0,  35, 200, 247, 251, 134,   4,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   3,   3,   1,   0,  11, 211, 247, 249, 255, 189,  76,   0,\n",
       "           0,   4,   0,   2,   0, 169, 255, 255, 247,  47,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   6,   0,   0,   2,   0,  59, 205, 255, 240, 255, 182,  41,\n",
       "          56,  28,  33,  42, 239, 246, 251, 238, 157,   0,   1,   0,   0,\n",
       "           0,   0],\n",
       "        [  2,   1,   0,   0,   2,  10,   0, 104, 239, 255, 240, 255, 253,\n",
       "         247, 237, 255, 255, 250, 255, 239, 255, 100,   0,   1,   0,   0,\n",
       "           0,   0],\n",
       "        [  1,   0,   3,   0,   0,   7,   0,   4, 114, 255, 255, 255, 255,\n",
       "         247, 249, 253, 251, 254, 237, 251,  89,   0,   0,   1,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   9,   0,   0,   1,  13,   0,  14, 167, 255, 246, 253,\n",
       "         255, 255, 254, 242, 255, 244,  61,   0,  19,   0,   1,   0,   0,\n",
       "           0,   0],\n",
       "        [  2,   1,   7,   0,   0,   4,   0,  14,   0,  27,  61, 143, 255,\n",
       "         255, 252, 255, 149,  21,   6,  16,   0,   0,   7,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0]], dtype=uint8),\n",
       " 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0118, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0078,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.0118, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0078,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.0118, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0078,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]),\n",
       " 0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the Feed-Forward neural network architecture\n",
    "class FeedForwardNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeedForwardNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 32)\n",
    "        self.fc2 = nn.Linear(32, 32)\n",
    "        self.fc3 = nn.Linear(32, 32)\n",
    "        self.fc4 = nn.Linear(32, 32)\n",
    "        self.fc5 = nn.Linear(32, 10)  # Output layer with 10 classes (assuming MNIST dataset)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten the input\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model, loss function, and optimizer\n",
    "model = FeedForwardNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0003)\n",
    "\n",
    "# Training loop\n",
    "  # You can adjust this as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/60], Loss: 2.247560977935791\n",
      "Epoch 0, Accuracy on Training Set: 0.1465873015873016\n",
      "Epoch [1/60], Validation Loss: 2.281677484512329\n",
      "Epoch 0, Accuracy on Validation Set: 0.18071428571428572\n",
      "Epoch [2/60], Loss: 2.105684757232666\n",
      "Epoch 1, Accuracy on Training Set: 0.20846560846560847\n",
      "Epoch [2/60], Validation Loss: 2.072467088699341\n",
      "Epoch 1, Accuracy on Validation Set: 0.2509523809523809\n",
      "Epoch [3/60], Loss: 1.9379907846450806\n",
      "Epoch 2, Accuracy on Training Set: 0.28224867724867725\n",
      "Epoch [3/60], Validation Loss: 1.8139773607254028\n",
      "Epoch 2, Accuracy on Validation Set: 0.3404761904761905\n",
      "Epoch [4/60], Loss: 1.7771236896514893\n",
      "Epoch 3, Accuracy on Training Set: 0.37767195767195766\n",
      "Epoch [4/60], Validation Loss: 1.7569791078567505\n",
      "Epoch 3, Accuracy on Validation Set: 0.44571428571428573\n",
      "Epoch [5/60], Loss: 1.5582245588302612\n",
      "Epoch 4, Accuracy on Training Set: 0.48732804232804233\n",
      "Epoch [5/60], Validation Loss: 1.435165286064148\n",
      "Epoch 4, Accuracy on Validation Set: 0.5504761904761905\n",
      "Epoch [6/60], Loss: 1.3883789777755737\n",
      "Epoch 5, Accuracy on Training Set: 0.5813492063492064\n",
      "Epoch [6/60], Validation Loss: 1.2849223613739014\n",
      "Epoch 5, Accuracy on Validation Set: 0.6223809523809524\n",
      "Epoch [7/60], Loss: 1.1645135879516602\n",
      "Epoch 6, Accuracy on Training Set: 0.6393915343915344\n",
      "Epoch [7/60], Validation Loss: 1.0739672183990479\n",
      "Epoch 6, Accuracy on Validation Set: 0.6664285714285715\n",
      "Epoch [8/60], Loss: 1.0861550569534302\n",
      "Epoch 7, Accuracy on Training Set: 0.6838624338624338\n",
      "Epoch [8/60], Validation Loss: 0.9541808366775513\n",
      "Epoch 7, Accuracy on Validation Set: 0.7007142857142857\n",
      "Epoch [9/60], Loss: 0.9275605082511902\n",
      "Epoch 8, Accuracy on Training Set: 0.7171693121693121\n",
      "Epoch [9/60], Validation Loss: 0.9970241785049438\n",
      "Epoch 8, Accuracy on Validation Set: 0.7321428571428571\n",
      "Epoch [10/60], Loss: 0.921472430229187\n",
      "Epoch 9, Accuracy on Training Set: 0.742010582010582\n",
      "Epoch [10/60], Validation Loss: 0.7794488072395325\n",
      "Epoch 9, Accuracy on Validation Set: 0.7509523809523809\n",
      "Epoch [11/60], Loss: 0.8470534086227417\n",
      "Epoch 10, Accuracy on Training Set: 0.7619312169312169\n",
      "Epoch [11/60], Validation Loss: 0.9826539158821106\n",
      "Epoch 10, Accuracy on Validation Set: 0.7714285714285715\n",
      "Epoch [12/60], Loss: 0.7213308215141296\n",
      "Epoch 11, Accuracy on Training Set: 0.7787301587301587\n",
      "Epoch [12/60], Validation Loss: 0.6973453760147095\n",
      "Epoch 11, Accuracy on Validation Set: 0.7847619047619048\n",
      "Epoch [13/60], Loss: 0.685954749584198\n",
      "Epoch 12, Accuracy on Training Set: 0.7917460317460318\n",
      "Epoch [13/60], Validation Loss: 0.7741795778274536\n",
      "Epoch 12, Accuracy on Validation Set: 0.7973809523809524\n",
      "Epoch [14/60], Loss: 0.7370893359184265\n",
      "Epoch 13, Accuracy on Training Set: 0.8038359788359788\n",
      "Epoch [14/60], Validation Loss: 0.6438866853713989\n",
      "Epoch 13, Accuracy on Validation Set: 0.8047619047619048\n",
      "Epoch [15/60], Loss: 0.770456075668335\n",
      "Epoch 14, Accuracy on Training Set: 0.8131481481481482\n",
      "Epoch [15/60], Validation Loss: 0.5523307919502258\n",
      "Epoch 14, Accuracy on Validation Set: 0.8135714285714286\n",
      "Epoch [16/60], Loss: 0.5781955718994141\n",
      "Epoch 15, Accuracy on Training Set: 0.8210846560846561\n",
      "Epoch [16/60], Validation Loss: 0.4587242007255554\n",
      "Epoch 15, Accuracy on Validation Set: 0.8204761904761905\n",
      "Epoch [17/60], Loss: 0.5392756462097168\n",
      "Epoch 16, Accuracy on Training Set: 0.828015873015873\n",
      "Epoch [17/60], Validation Loss: 0.5877559185028076\n",
      "Epoch 16, Accuracy on Validation Set: 0.8266666666666667\n",
      "Epoch [18/60], Loss: 0.5915476679801941\n",
      "Epoch 17, Accuracy on Training Set: 0.8334920634920635\n",
      "Epoch [18/60], Validation Loss: 0.6165767312049866\n",
      "Epoch 17, Accuracy on Validation Set: 0.8361904761904762\n",
      "Epoch [19/60], Loss: 0.46725916862487793\n",
      "Epoch 18, Accuracy on Training Set: 0.8392857142857143\n",
      "Epoch [19/60], Validation Loss: 0.5009093880653381\n",
      "Epoch 18, Accuracy on Validation Set: 0.8397619047619047\n",
      "Epoch [20/60], Loss: 0.5469510555267334\n",
      "Epoch 19, Accuracy on Training Set: 0.8436243386243386\n",
      "Epoch [20/60], Validation Loss: 0.4336126148700714\n",
      "Epoch 19, Accuracy on Validation Set: 0.8459523809523809\n",
      "Epoch [21/60], Loss: 0.5449932813644409\n",
      "Epoch 20, Accuracy on Training Set: 0.849047619047619\n",
      "Epoch [21/60], Validation Loss: 0.4343993365764618\n",
      "Epoch 20, Accuracy on Validation Set: 0.8485714285714285\n",
      "Epoch [22/60], Loss: 0.4841528534889221\n",
      "Epoch 21, Accuracy on Training Set: 0.8533068783068783\n",
      "Epoch [22/60], Validation Loss: 0.4497683346271515\n",
      "Epoch 21, Accuracy on Validation Set: 0.8535714285714285\n",
      "Epoch [23/60], Loss: 0.5640774965286255\n",
      "Epoch 22, Accuracy on Training Set: 0.8567195767195768\n",
      "Epoch [23/60], Validation Loss: 0.5028870105743408\n",
      "Epoch 22, Accuracy on Validation Set: 0.8576190476190476\n",
      "Epoch [24/60], Loss: 0.49410414695739746\n",
      "Epoch 23, Accuracy on Training Set: 0.8597619047619047\n",
      "Epoch [24/60], Validation Loss: 0.6150591373443604\n",
      "Epoch 23, Accuracy on Validation Set: 0.8616666666666667\n",
      "Epoch [25/60], Loss: 0.46136730909347534\n",
      "Epoch 24, Accuracy on Training Set: 0.8634920634920635\n",
      "Epoch [25/60], Validation Loss: 0.48473840951919556\n",
      "Epoch 24, Accuracy on Validation Set: 0.8640476190476191\n",
      "Epoch [26/60], Loss: 0.49916526675224304\n",
      "Epoch 25, Accuracy on Training Set: 0.8667989417989418\n",
      "Epoch [26/60], Validation Loss: 0.26977863907814026\n",
      "Epoch 25, Accuracy on Validation Set: 0.8664285714285714\n",
      "Epoch [27/60], Loss: 0.4068455696105957\n",
      "Epoch 26, Accuracy on Training Set: 0.8694179894179894\n",
      "Epoch [27/60], Validation Loss: 0.4800979793071747\n",
      "Epoch 26, Accuracy on Validation Set: 0.8664285714285714\n",
      "Epoch [28/60], Loss: 0.5075625777244568\n",
      "Epoch 27, Accuracy on Training Set: 0.8712962962962963\n",
      "Epoch [28/60], Validation Loss: 0.44187548756599426\n",
      "Epoch 27, Accuracy on Validation Set: 0.8695238095238095\n",
      "Epoch [29/60], Loss: 0.41319695115089417\n",
      "Epoch 28, Accuracy on Training Set: 0.8739153439153439\n",
      "Epoch [29/60], Validation Loss: 0.5186400413513184\n",
      "Epoch 28, Accuracy on Validation Set: 0.8707142857142857\n",
      "Epoch [30/60], Loss: 0.3623712658882141\n",
      "Epoch 29, Accuracy on Training Set: 0.8759259259259259\n",
      "Epoch [30/60], Validation Loss: 0.366630494594574\n",
      "Epoch 29, Accuracy on Validation Set: 0.8697619047619047\n",
      "Epoch [31/60], Loss: 0.43841981887817383\n",
      "Epoch 30, Accuracy on Training Set: 0.8784126984126984\n",
      "Epoch [31/60], Validation Loss: 0.5551216006278992\n",
      "Epoch 30, Accuracy on Validation Set: 0.8738095238095238\n",
      "Epoch [32/60], Loss: 0.48945167660713196\n",
      "Epoch 31, Accuracy on Training Set: 0.879973544973545\n",
      "Epoch [32/60], Validation Loss: 0.47531858086586\n",
      "Epoch 31, Accuracy on Validation Set: 0.8728571428571429\n",
      "Epoch [33/60], Loss: 0.3525536060333252\n",
      "Epoch 32, Accuracy on Training Set: 0.8822222222222222\n",
      "Epoch [33/60], Validation Loss: 0.4545544385910034\n",
      "Epoch 32, Accuracy on Validation Set: 0.8745238095238095\n",
      "Epoch [34/60], Loss: 0.32771608233451843\n",
      "Epoch 33, Accuracy on Training Set: 0.8837566137566137\n",
      "Epoch [34/60], Validation Loss: 0.421919047832489\n",
      "Epoch 33, Accuracy on Validation Set: 0.8761904761904762\n",
      "Epoch [35/60], Loss: 0.4079548716545105\n",
      "Epoch 34, Accuracy on Training Set: 0.8856878306878306\n",
      "Epoch [35/60], Validation Loss: 0.644338071346283\n",
      "Epoch 34, Accuracy on Validation Set: 0.8773809523809524\n",
      "Epoch [36/60], Loss: 0.32775962352752686\n",
      "Epoch 35, Accuracy on Training Set: 0.8865873015873016\n",
      "Epoch [36/60], Validation Loss: 0.2782748341560364\n",
      "Epoch 35, Accuracy on Validation Set: 0.8795238095238095\n",
      "Epoch [37/60], Loss: 0.3146424889564514\n",
      "Epoch 36, Accuracy on Training Set: 0.888095238095238\n",
      "Epoch [37/60], Validation Loss: 0.34607964754104614\n",
      "Epoch 36, Accuracy on Validation Set: 0.8809523809523809\n",
      "Epoch [38/60], Loss: 0.35070177912712097\n",
      "Epoch 37, Accuracy on Training Set: 0.8890740740740741\n",
      "Epoch [38/60], Validation Loss: 0.3993188440799713\n",
      "Epoch 37, Accuracy on Validation Set: 0.8823809523809524\n",
      "Epoch [39/60], Loss: 0.3326568901538849\n",
      "Epoch 38, Accuracy on Training Set: 0.8917195767195767\n",
      "Epoch [39/60], Validation Loss: 0.2331348955631256\n",
      "Epoch 38, Accuracy on Validation Set: 0.8835714285714286\n",
      "Epoch [40/60], Loss: 0.39985400438308716\n",
      "Epoch 39, Accuracy on Training Set: 0.8922222222222222\n",
      "Epoch [40/60], Validation Loss: 0.45097440481185913\n",
      "Epoch 39, Accuracy on Validation Set: 0.8852380952380953\n",
      "Epoch [41/60], Loss: 0.2934320271015167\n",
      "Epoch 40, Accuracy on Training Set: 0.8942592592592593\n",
      "Epoch [41/60], Validation Loss: 0.34978145360946655\n",
      "Epoch 40, Accuracy on Validation Set: 0.8895238095238095\n",
      "Epoch [42/60], Loss: 0.3137235939502716\n",
      "Epoch 41, Accuracy on Training Set: 0.8951851851851852\n",
      "Epoch [42/60], Validation Loss: 0.37250518798828125\n",
      "Epoch 41, Accuracy on Validation Set: 0.8904761904761904\n",
      "Epoch [43/60], Loss: 0.4385260045528412\n",
      "Epoch 42, Accuracy on Training Set: 0.895978835978836\n",
      "Epoch [43/60], Validation Loss: 0.38889822363853455\n",
      "Epoch 42, Accuracy on Validation Set: 0.8902380952380953\n",
      "Epoch [44/60], Loss: 0.38278546929359436\n",
      "Epoch 43, Accuracy on Training Set: 0.8977248677248677\n",
      "Epoch [44/60], Validation Loss: 0.4543478190898895\n",
      "Epoch 43, Accuracy on Validation Set: 0.8919047619047619\n",
      "Epoch [45/60], Loss: 0.406209260225296\n",
      "Epoch 44, Accuracy on Training Set: 0.8982275132275133\n",
      "Epoch [45/60], Validation Loss: 0.3845062255859375\n",
      "Epoch 44, Accuracy on Validation Set: 0.8933333333333333\n",
      "Epoch [46/60], Loss: 0.3402540683746338\n",
      "Epoch 45, Accuracy on Training Set: 0.9\n",
      "Epoch [46/60], Validation Loss: 0.28072425723075867\n",
      "Epoch 45, Accuracy on Validation Set: 0.8928571428571429\n",
      "Epoch [47/60], Loss: 0.3301641643047333\n",
      "Epoch 46, Accuracy on Training Set: 0.9005555555555556\n",
      "Epoch [47/60], Validation Loss: 0.40459614992141724\n",
      "Epoch 46, Accuracy on Validation Set: 0.8957142857142857\n",
      "Epoch [48/60], Loss: 0.28355470299720764\n",
      "Epoch 47, Accuracy on Training Set: 0.9015873015873016\n",
      "Epoch [48/60], Validation Loss: 0.283687025308609\n",
      "Epoch 47, Accuracy on Validation Set: 0.8969047619047619\n",
      "Epoch [49/60], Loss: 0.30546045303344727\n",
      "Epoch 48, Accuracy on Training Set: 0.9023809523809524\n",
      "Epoch [49/60], Validation Loss: 0.27792003750801086\n",
      "Epoch 48, Accuracy on Validation Set: 0.8964285714285715\n",
      "Epoch [50/60], Loss: 0.2835582196712494\n",
      "Epoch 49, Accuracy on Training Set: 0.9035714285714286\n",
      "Epoch [50/60], Validation Loss: 0.22654865682125092\n",
      "Epoch 49, Accuracy on Validation Set: 0.8990476190476191\n",
      "Epoch [51/60], Loss: 0.30550795793533325\n",
      "Epoch 50, Accuracy on Training Set: 0.9055291005291005\n",
      "Epoch [51/60], Validation Loss: 0.17487318813800812\n",
      "Epoch 50, Accuracy on Validation Set: 0.8990476190476191\n",
      "Epoch [52/60], Loss: 0.35964587330818176\n",
      "Epoch 51, Accuracy on Training Set: 0.9057407407407407\n",
      "Epoch [52/60], Validation Loss: 0.34596750140190125\n",
      "Epoch 51, Accuracy on Validation Set: 0.9011904761904762\n",
      "Epoch [53/60], Loss: 0.4181106984615326\n",
      "Epoch 52, Accuracy on Training Set: 0.9061111111111111\n",
      "Epoch [53/60], Validation Loss: 0.3435041308403015\n",
      "Epoch 52, Accuracy on Validation Set: 0.9035714285714286\n",
      "Epoch [54/60], Loss: 0.275942325592041\n",
      "Epoch 53, Accuracy on Training Set: 0.9076984126984127\n",
      "Epoch [54/60], Validation Loss: 0.3220963478088379\n",
      "Epoch 53, Accuracy on Validation Set: 0.9047619047619048\n",
      "Epoch [55/60], Loss: 0.3071476221084595\n",
      "Epoch 54, Accuracy on Training Set: 0.9077777777777778\n",
      "Epoch [55/60], Validation Loss: 0.3691219091415405\n",
      "Epoch 54, Accuracy on Validation Set: 0.9042857142857142\n",
      "Epoch [56/60], Loss: 0.2864467203617096\n",
      "Epoch 55, Accuracy on Training Set: 0.9090211640211641\n",
      "Epoch [56/60], Validation Loss: 0.4053046405315399\n",
      "Epoch 55, Accuracy on Validation Set: 0.9040476190476191\n",
      "Epoch [57/60], Loss: 0.3931587040424347\n",
      "Epoch 56, Accuracy on Training Set: 0.9094179894179895\n",
      "Epoch [57/60], Validation Loss: 0.16958339512348175\n",
      "Epoch 56, Accuracy on Validation Set: 0.905952380952381\n",
      "Epoch [58/60], Loss: 0.2602430284023285\n",
      "Epoch 57, Accuracy on Training Set: 0.90994708994709\n",
      "Epoch [58/60], Validation Loss: 0.22702200710773468\n",
      "Epoch 57, Accuracy on Validation Set: 0.9078571428571428\n",
      "Epoch [59/60], Loss: 0.31758999824523926\n",
      "Epoch 58, Accuracy on Training Set: 0.910978835978836\n",
      "Epoch [59/60], Validation Loss: 0.38951873779296875\n",
      "Epoch 58, Accuracy on Validation Set: 0.9069047619047619\n",
      "Epoch [60/60], Loss: 0.34133100509643555\n",
      "Epoch 59, Accuracy on Training Set: 0.911084656084656\n",
      "Epoch [60/60], Validation Loss: 0.3444567322731018\n",
      "Epoch 59, Accuracy on Validation Set: 0.9064285714285715\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 60\n",
    "for epoch in range(num_epochs):\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    # print(\"hello epoch\")\n",
    "    custom_dataloader = CustomDataLoader(train_data_custom, 512)\n",
    "    for inputs, labels in custom_dataloader:\n",
    "        # print(\"hello data\")\n",
    "        inputs = torch.from_numpy(inputs).float()\n",
    "        labels = torch.from_numpy(labels).long()\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        # print(predicted)\n",
    "        # print(\"bleh\")\n",
    "        # print(labels)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        # print(\"total correct: \",total_correct)\n",
    "        # print(\"total samples: \",total_samples)\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    # print(\"epoch end\")\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}')\n",
    "    accuracy = total_correct / total_samples\n",
    "    print(f'Epoch {epoch}, Accuracy on Training Set: {accuracy}')\n",
    "\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    validation_dataloader = CustomDataLoader(val_data_custom, 512)\n",
    "    for inputs, labels in validation_dataloader:\n",
    "        # print(\"hello data\")\n",
    "        inputs = torch.from_numpy(inputs).float()\n",
    "        labels = torch.from_numpy(labels).long()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    # print(\"epoch end\")\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Loss: {loss.item()}')\n",
    "    accuracy = total_correct / total_samples\n",
    "    print(f'Epoch {epoch}, Accuracy on Validation Set: {accuracy}')\n",
    "\n",
    "\n",
    "# After training, you can use the model for predictions\n",
    "# Example:\n",
    "# test_inputs, test_labels = next(iter(test_dataloader))\n",
    "# test_inputs = torch.from_numpy(test_inputs).float()\n",
    "# predictions = model(test_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
